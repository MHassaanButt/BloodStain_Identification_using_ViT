{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impoprting Libraires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "VYFHwxzwT2AB",
    "outputId": "7e7bab91-d1df-470d-d06c-6e2e98513af7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\miniconda3\\envs\\hsi\\Lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import seaborn as sns\n",
    "import spectral\n",
    "import tensorflow as tf\n",
    "from keras.layers import (Conv3D,Conv2D, Dense, Dropout, Flatten, Input,\n",
    "                          Reshape)\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import np_utils\n",
    "from sklearn.decomposition import (IncrementalPCA, KernelPCA, PCA, SparsePCA,\n",
    "                                   TruncatedSVD)\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             cohen_kappa_score, confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import (Activation, Lambda, multiply)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from vit_keras import utils, vit\n",
    "import spectral.io.envi as envi\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "from operator import truediv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pnXXoPPeFCLd",
    "outputId": "6213a0ec-4706-496e-f141-0dfb10188bc3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\miniconda3\\envs\\hsi\\Lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "path='../../Datasets/HyperBlood/'\n",
    "output_dir = os.path.join(\"results/\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "HSID = \"E_1\"    ## 'A_1.hdr', 'B_1.hdr', 'C_1.hdr', 'D_1.hdr', 'E_1.hdr', 'E_7.hdr', \n",
    "                ## 'E_21.hdr', 'F_1.hdr.hdr', 'F_1a.hdr', 'F_1s.hdr', 'F_2.hdr', \n",
    "                ## 'F_2k.hdr', 'F_7.hdr', 'F_21.hdr'\n",
    "DLM = \"PCA\"     ## \"PCA\", \"iPCA\", \"SPCA\", \"KPCA\", \"SVD\"\n",
    "WS = 9          ## 9, 11, 13, 15, 17, 19, 21, 23, 25\n",
    "trRatio = 0.05 ##Percentage of Train Samples\n",
    "vrRatio = 0.05 ##Percentage of Validation Samples\n",
    "teRatio = 0.90 ##Percentage of Test Samples\n",
    "k = 15\n",
    "\n",
    "adam = legacy.Adam(lr=1e-3, decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uiIpElfecJRr"
   },
   "outputs": [],
   "source": [
    "## Get HSI Data and Ground Truths\n",
    "## Get HSI Data\n",
    "def get_data(name,remove_bands=True,clean=True, path=path):\n",
    "    \"\"\"\n",
    "    Input: name: name; remove_bands: if True, noisy bands are removed (leaving 113 bands)\n",
    "    clean: if True, remove damaged line\n",
    "    Output: data, wavelenghts as numpy arrays (float32)\n",
    "    \"\"\"\n",
    "    name = convert_name(name)\n",
    "    filename = \"{}data/{}\".format(path,name)\n",
    "    hsimage = envi.open('{}.hdr'.format(filename),'{}.float'.format(filename))\n",
    "    wavs = np.asarray(hsimage.bands.centers) \n",
    "    data = np.asarray(hsimage[:,:,:],dtype=np.float32)\n",
    "    #removal of damaged sensor line\n",
    "    if clean and name!='F_2k':\n",
    "        data = np.delete(data,445,0)\n",
    "    if not remove_bands:\n",
    "        return data,wavs\n",
    "    return data[:,:,get_good_indices(name)],wavs[get_good_indices(name)]\n",
    "\n",
    "## Get Ground Truths\n",
    "def get_anno(name,remove_uncertain_blood=True,clean=True, path=path):\n",
    "    \"\"\"\n",
    "    Returns annotation (GT) for data files as 2D int numpy array\n",
    "    Classes: 0 - background; 1 - blood; 2 - ketchup; 3 - artificial blood; 4 - beetroot juice\n",
    "    5 - poster paint; 6 - tomato concentrate; 7 - acrtylic paint; 8 - uncertain blood;\n",
    "    Input: name: name; clean: if True, remove damaged line; \n",
    "    remove_uncertain_blood: if True, removes class 8 \n",
    "    Output: annotation as numpy 2D array \n",
    "    \"\"\"\n",
    "    name = convert_name(name)\n",
    "    filename = \"{}anno/{}\".format(path,name)\n",
    "    anno = np.load(filename+'.npz')['gt']\n",
    "    #removal of damaged sensor line\n",
    "    if clean and name!='F_2k':\n",
    "        anno = np.delete(anno,445,0)\n",
    "    #remove uncertain blood + technical classes\n",
    "    if remove_uncertain_blood:\n",
    "        anno[anno>7]=0\n",
    "    else:\n",
    "        anno[anno>8]=0\n",
    "    return anno\n",
    "\n",
    "\n",
    "def blood_loader(path, name):\n",
    "    \"\"\"\n",
    "    returns data and annotation, removing classes that are not present in all images\n",
    "    Input: path: data path; name: image name\n",
    "    Output:img: data cube; gt: annotation with correct classes; \n",
    "    rgb_bands: three bands used for rgb visualisation\n",
    "    ignored_labels: labels that should be ignored [0 for background] \n",
    "    label_values: class labels\n",
    "    \"\"\"\n",
    "    img = np.asarray(get_data(name, path=path)[0], dtype='float32')\n",
    "    gt = get_anno(name, path=path).astype('uint8')\n",
    "    # remove beetroot juice (is only on frames images so in our\n",
    "    # classification experiments we removed it from pictures)\n",
    "    gt = np.where(gt == 4, 0, gt)\n",
    "    # renumbering after removing beetroot juice\n",
    "    for element in [5, 6, 7]:\n",
    "        gt = np.where(gt == element, element - 1, gt)\n",
    "    label_values = [\"unclassified\",\n",
    "                    \"blood\",\n",
    "                    \"ketchup\",\n",
    "                    \"artificial blood\",\n",
    "                    \"poster paint\",\n",
    "                    \"tomato concentrate\",\n",
    "                    \"acrylic paint\"]\n",
    "    rgb_bands, ignored_labels = (47, 31, 15), [0]\n",
    "    return img, gt, rgb_bands, ignored_labels, label_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XTwNvyv0CrkW"
   },
   "outputs": [],
   "source": [
    "def convert_name(name):\n",
    "    \"\"\"\n",
    "    Ensures that the name is in the filename format\n",
    "    Parameters: name: name\n",
    "    Output: cleaned name\n",
    "    \"\"\"\n",
    "    name = name.replace('(','_')\n",
    "    name = name.replace(')','')\n",
    "    return name\n",
    "\n",
    "def get_good_indices(name=None):\n",
    "    \"\"\"\n",
    "    Input: name: name\n",
    "    Output: numpy array of good indices         \n",
    "    \"\"\"\n",
    "    name = convert_name(name)\n",
    "    if name!='F_2k':\n",
    "        indices = np.arange(128)\n",
    "        indices = indices[5:-7]\n",
    "    else:\n",
    "        indices = np.arange(116)    \n",
    "    indices=np.delete(indices,[43,44,45])\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7OKY2h4YScVI"
   },
   "outputs": [],
   "source": [
    "## Load HSI Dataset\n",
    "def LoadHSIData(method):\n",
    "    ## List of HSI Dataasets\n",
    "    HSI_list = ['A_1.hdr', 'B_1.hdr', 'C_1.hdr', 'D_1.hdr', 'E_1.hdr', 'E_7.hdr', \n",
    "                'E_21.hdr', 'F_1.hdr.hdr', 'F_1a.hdr', 'F_1s.hdr', 'F_2.hdr', \n",
    "                'F_2k.hdr', 'F_7.hdr', 'F_21.hdr']\n",
    "    for i in range(len(HSI_list)):\n",
    "        file_name = HSI_list[i].split('.')[0]\n",
    "        data_path = os.path.join(os.getcwd(),'../../Datasets/HyperBlood/data'+str(file_name))\n",
    "        # print(data_path)\n",
    "        if os.path.exists(data_path) == False:\n",
    "            # print(\"Data file from %s to %s\" % (HSI_list[i], data_path))\n",
    "            # #urllib.request.urlretrieve(url=HSI_url[i], filename=data_path)\n",
    "            print(str(file_name)+\" is Successfully Found\")\n",
    "        else:\n",
    "            print(str(file_name) + \" already exist\")\n",
    "    data_path = os.path.join(os.getcwd(),'../../Datasets/HyperBlood/data')\n",
    "    data_path1 = os.path.join(os.getcwd(),'../../Datasets/HyperBlood/anno')\n",
    "    if method == 'A_1':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'B_1':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'C_1':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'D_1':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')    \n",
    "    elif method == 'E_1':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'E_7':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'E_21':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'F_1':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'F_1a':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'F_1s':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'F_2':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'F_2k':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')  \n",
    "    elif method == 'F_7':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'F_21':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8') \n",
    "    # remove beetroot juice (is only on frames images so in our\n",
    "    # classification experiments we removed it from pictures)\n",
    "    # GT = np.where(GT == 4, 0, GT)\n",
    "    # # renumbering after removing beetroot juice\n",
    "    # for element in [5, 6, 7]:\n",
    "    #     GT = np.where(GT == element, element - 1, GT)\n",
    "    # rgb_bands, ignored_labels = (47, 31, 15), [0]\n",
    "    return HSI, GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UdNQxxanJuQz"
   },
   "outputs": [],
   "source": [
    "## Dimension Reduction\n",
    "def DLMethod(method, HSI, NC = 75):\n",
    "    RHSI = np.reshape(HSI, (-1, HSI.shape[2]))\n",
    "    if method == 'PCA': ## PCA\n",
    "        pca = PCA(n_components = NC, whiten = True)\n",
    "        RHSI = pca.fit_transform(RHSI)\n",
    "        RHSI = np.reshape(RHSI, (HSI.shape[0], HSI.shape[1], NC))\n",
    "    elif method == 'iPCA': ## Incremental PCA\n",
    "        n_batches = 256\n",
    "        inc_pca = IncrementalPCA(n_components = NC)\n",
    "        for X_batch in np.array_split(RHSI, n_batches):\n",
    "            inc_pca.partial_fit(X_batch)\n",
    "        X_ipca = inc_pca.transform(RHSI)\n",
    "        RHSI = np.reshape(X_ipca, (HSI.shape[0], HSI.shape[1], NC))\n",
    "    elif method == 'KPCA': ## Kernel PCA\n",
    "        kpca = KernelPCA(kernel = \"rbf\", n_components = NC, gamma = None, \n",
    "                         fit_inverse_transform = True, random_state = 2019, \n",
    "                         n_jobs=1)\n",
    "        kpca.fit(RHSI)\n",
    "        RHSI = kpca.transform(RHSI)\n",
    "        RHSI = np.reshape(RHSI, (HSI.shape[0], HSI.shape[1], NC))\n",
    "    elif method == 'SPCA': ## Sparse PCA\n",
    "        sparsepca = SparsePCA(n_components = NC, alpha=0.0001, random_state=2019, n_jobs=-1)\n",
    "        sparsepca.fit(RHSI)\n",
    "        RHSI = sparsepca.transform(RHSI)\n",
    "        RHSI = np.reshape(RHSI, (HSI.shape[0], HSI.shape[1], NC))\n",
    "    elif method == 'SVD': ## Singular Value Decomposition\n",
    "        SVD_ = TruncatedSVD(n_components = NC,algorithm = 'randomized', \n",
    "                            random_state = 2019, n_iter=5)\n",
    "        SVD_.fit(RHSI)\n",
    "        RHSI = SVD_.transform(RHSI)\n",
    "        RHSI = np.reshape(RHSI, (HSI.shape[0], HSI.shape[1], NC))\n",
    "    return RHSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CmLBk7cJD40S"
   },
   "outputs": [],
   "source": [
    "## Padding and Spatial Patchs\n",
    "def ZeroPad(HSI, margin = 2):\n",
    "    NHSI = np.zeros((HSI.shape[0] + 2 * margin, HSI.shape[1] + 2* margin, HSI.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    NHSI[x_offset:HSI.shape[0] + x_offset, y_offset:HSI.shape[1] + y_offset, :] = HSI\n",
    "    return NHSI\n",
    "\n",
    "## Compute the Patch to Prepare for Ground Truths\n",
    "def Patch(HSI,height_index,width_index):\n",
    "    height_slice = slice(height_index, height_index+WS)\n",
    "    width_slice = slice(width_index, width_index+WS)\n",
    "    patch = HSI[height_slice, width_slice, :]\n",
    "    return patch\n",
    "    \n",
    "def ImageCubes(HSI, GT, WS = 5, removeZeroLabels = True):\n",
    "    margin = int((WS - 1) / 2)\n",
    "    zeroPaddedX = ZeroPad(HSI, margin = margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((HSI.shape[0] * HSI.shape[1], WS, WS, HSI.shape[2]))\n",
    "    patchesLabels = np.zeros((HSI.shape[0] * HSI.shape[1]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = GT[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
    "        patchesLabels = patchesLabels[patchesLabels>0]\n",
    "        patchesLabels -= 1\n",
    "    return patchesData, patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "c073lR_nEBF7"
   },
   "outputs": [],
   "source": [
    "## Classification Reports\n",
    "def ClassificationReports(TeC, Te_Pred):\n",
    "    Te_Pred = np.argmax(Te_Pred, axis=1)\n",
    "    target_names = [\"blood\",\n",
    "                    \"ketchup\",\n",
    "                    \"artificial blood\",\n",
    "                    \"poster paint\",\n",
    "                    \"tomato concentrate\",\n",
    "                    \"acrylic paint\"]\n",
    "    classification = classification_report(np.argmax(TeC, axis=1), Te_Pred, target_names = target_names)\n",
    "    oa = accuracy_score(np.argmax(TeC, axis=1), Te_Pred)\n",
    "    confusion = confusion_matrix(np.argmax(TeC, axis=1), Te_Pred)\n",
    "    counter = confusion.shape[0]\n",
    "    list_diag = np.diag(confusion)\n",
    "    list_raw_sum = np.sum(confusion, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    aa = np.mean(each_acc)\n",
    "    kappa = cohen_kappa_score(np.argmax(TeC, axis=1), Te_Pred)\n",
    "    return classification, confusion, oa*100, each_acc*100, aa*100, kappa*100, target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "a0e_9RypEiH4"
   },
   "outputs": [],
   "source": [
    "## Writing Classification Results\n",
    "def CSVResults(file_name, classification, confusion, Tr_Time, Te_Time, DL_Time, kappa, oa, aa):\n",
    "    classification = str(classification)\n",
    "    confusion = str(confusion)\n",
    "    with open(file_name, 'w') as CSV_file:\n",
    "        \n",
    "        CSV_file.write('{} Tr_Time'.format(Tr_Time))\n",
    "        CSV_file.write('\\n')\n",
    "        CSV_file.write('{} Te_Time'.format(Te_Time))\n",
    "        CSV_file.write('\\n')\n",
    "        CSV_file.write('{} DL_Time'.format(DL_Time))\n",
    "        CSV_file.write('\\n')\n",
    "        CSV_file.write('{} Kappa accuracy (%)'.format(kappa))\n",
    "        CSV_file.write('\\n')\n",
    "        CSV_file.write('{} Overall accuracy (%)'.format(oa))\n",
    "        CSV_file.write('\\n')\n",
    "        CSV_file.write('{} Average accuracy (%)'.format(aa))\n",
    "        CSV_file.write('\\n')\n",
    "        CSV_file.write('\\n')\n",
    "        CSV_file.write('{}'.format(classification))\n",
    "        CSV_file.write('\\n')\n",
    "        CSV_file.write('{}'.format(confusion))\n",
    "        return CSV_file\n",
    "    \n",
    "## Plot Ground Truths \n",
    "def GT_Plot(RDHSI, GT, model, WS):\n",
    "    height, width = np.shape(GT)\n",
    "    RDHSI = ZeroPad(RDHSI, WS//2) ## Zero Padding\n",
    "    ## Calculate the predicted Ground Truths\n",
    "    outputs = np.zeros((height, width))\n",
    "    for AA in range(height):\n",
    "        for BB in range(width):\n",
    "            \n",
    "            target = int(GT[AA,BB])\n",
    "            if target == 0:\n",
    "                continue\n",
    "            else :\n",
    "                image_patch = Patch(RDHSI,AA,BB)\n",
    "                X_test_image = image_patch.reshape(1,image_patch.shape[0],\n",
    "                                             image_patch.shape[1],\n",
    "                                             image_patch.shape[2],\n",
    "                                             1).astype('float32')\n",
    "                prediction = (model.predict(X_test_image))\n",
    "                prediction = np.argmax(prediction, axis=1)\n",
    "                outputs[AA][BB] = prediction+1\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tPIeFTGkEw08"
   },
   "outputs": [],
   "source": [
    "## Plot and Save Confusion Matrix\n",
    "def Conf_Mat(Te_Pred, TeC, target_names):\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "    Te_Pred = np.argmax(Te_Pred, axis=1)\n",
    "    confusion = confusion_matrix(np.argmax(TeC, axis=1), Te_Pred, labels=np.unique(np.argmax(TeC, axis=1)))\n",
    "    cm_sum = np.sum(confusion, axis=1, keepdims=True)\n",
    "    cm_perc = confusion / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(confusion).astype(str)\n",
    "    nrows, ncols = confusion.shape\n",
    "    for l in range(nrows):\n",
    "        for m in range(ncols):\n",
    "            c = confusion[l, m]\n",
    "            p = cm_perc[l, m]\n",
    "            if l == m:\n",
    "                s = cm_sum[l]\n",
    "                annot[l, m] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[l, m] = ''\n",
    "            else:\n",
    "                annot[l, m] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(confusion, index=np.unique(target_names), columns=np.unique(target_names))\n",
    "    return cm, annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_1 is Successfully Found\n",
      "B_1 is Successfully Found\n",
      "C_1 is Successfully Found\n",
      "D_1 is Successfully Found\n",
      "E_1 is Successfully Found\n",
      "E_7 is Successfully Found\n",
      "E_21 is Successfully Found\n",
      "F_1 is Successfully Found\n",
      "F_1a is Successfully Found\n",
      "F_1s is Successfully Found\n",
      "F_2 is Successfully Found\n",
      "F_2k is Successfully Found\n",
      "F_7 is Successfully Found\n",
      "F_21 is Successfully Found\n",
      "# of Dimensions 15\n",
      "Shape of HSI (519, 696, 113)\n",
      "Shape of GT (519, 696)\n",
      "Name of Classes [0 1 2 3 5 6 7]\n",
      "# of Classes 7\n"
     ]
    }
   ],
   "source": [
    "HSI, GT = LoadHSIData(HSID)\n",
    "\n",
    "print(\"# of Dimensions\", k)          ## Dimensions\n",
    "print(\"Shape of HSI\", HSI.shape)\n",
    "print(\"Shape of GT\", GT.shape)\n",
    "# UC = np.unique(label_values)\n",
    "UC = np.unique(GT)\n",
    "print(\"Name of Classes\", UC)\n",
    "Num_Classes = len(UC)\n",
    "print(\"# of Classes\", Num_Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yZ4HQLx4GLW_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DL_Time 1.1682512760162354\n"
     ]
    }
   ],
   "source": [
    "## Reduce the Dimensionality\n",
    "start = time.time()\n",
    "RDHSI = DLMethod(DLM, HSI, NC = k)\n",
    "end = time.time()\n",
    "DL_Time = end - start\n",
    "print(\"DL_Time\",DL_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ODRw_s36KV5V",
    "outputId": "00fe46a1-38af-4ad1-d491-1cabfb7fc854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of HSI (33804, 9, 9, 15)\n",
      "Shape of GT (33804,)\n"
     ]
    }
   ],
   "source": [
    "## Create Image Cubes for Model Building\n",
    "CRDHSI, CGT = ImageCubes(RDHSI, GT, WS = WS)\n",
    "print(\"Shape of HSI\", CRDHSI.shape)\n",
    "print(\"Shape of GT\", CGT.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WKGHTFPLFZzv",
    "outputId": "3c0607f2-b4fa-4348-88df-df7426a395f1"
   },
   "source": [
    "## Split Train and Test sets\n",
    "Tr, Te, TrC, TeC = TrTeSplit(CRDHSI, CGT, TeRatio)\n",
    "## Split Train and Validation\n",
    "Tr, Va, TrC, VaC = TrTeSplit(Tr, TrC, VeRatio)\n",
    "## Reshape Train, Validation, and Test sets\n",
    "Tr = Tr.reshape(-1, WS, WS, k, 1)\n",
    "print('Tr', Tr.shape)\n",
    "TrC = np_utils.to_categorical(TrC)\n",
    "print('TrC', TrC.shape)\n",
    "Va = Va.reshape(-1, WS, WS, k, 1)\n",
    "print('Va', Va.shape)\n",
    "VaC = np_utils.to_categorical(VaC)\n",
    "print('VaC', VaC.shape)\n",
    "Te = Te.reshape(-1, WS, WS, k, 1)\n",
    "print('Te', Te.shape)\n",
    "TeC = np_utils.to_categorical(TeC)\n",
    "print('TeC', TeC.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tr (1690, 9, 9, 15, 1)\n",
      "TrC (1690, 7)\n",
      "Va (1690, 9, 9, 15, 1)\n",
      "VaC (1690, 7)\n",
      "Te (30424, 9, 9, 15, 1)\n",
      "TeC (30424, 7)\n",
      "Train Percentage: 5.0\n",
      "Val Percentage: 5.0\n",
      "Test Percentage: 90.0\n"
     ]
    }
   ],
   "source": [
    "def TrTeSplit(HSI, GT, trRatio, vrRatio, teRatio, randomState=345):\n",
    "    # Split into train and test sets\n",
    "    Tr, Te, TrC, TeC = train_test_split(HSI, GT, test_size=teRatio,\n",
    "                                        random_state=randomState, stratify=GT)\n",
    "    # Calculate the validation ratio based on the updated test and train ratios\n",
    "    totalTrRatio = trRatio + vrRatio\n",
    "    new_vrRatio = vrRatio / totalTrRatio\n",
    "    # Split train set into train and validation sets\n",
    "    Tr, Va, TrC, VaC = train_test_split(Tr, TrC, test_size=new_vrRatio,\n",
    "                                        random_state=randomState, stratify=TrC)\n",
    "    # Calculate the percentages of train, validation, and test sets\n",
    "    trPercentage = round(trRatio * 100, 1)\n",
    "    vrPercentage = round(vrRatio * 100, 1)\n",
    "    tePercentage = round(teRatio * 100, 1)\n",
    "    return Tr, Va, Te, TrC, VaC, TeC, trPercentage, vrPercentage, tePercentage\n",
    "\n",
    "# trRatio = 0.11 \n",
    "# vrRatio = 0.11 \n",
    "# teRatio = 0.78 \n",
    "Tr, Va, Te, TrC, VaC, TeC, TrPercentage, VaPercentage, TePercentage = TrTeSplit(CRDHSI, CGT, trRatio, vrRatio, teRatio)\n",
    "\n",
    "# Reshape train, validation, and test sets\n",
    "Tr = Tr.reshape(-1, WS, WS, k, 1)\n",
    "print('Tr', Tr.shape)\n",
    "TrC = np_utils.to_categorical(TrC)\n",
    "print('TrC', TrC.shape)\n",
    "\n",
    "Va = Va.reshape(-1, WS, WS, k, 1)\n",
    "print('Va', Va.shape)\n",
    "VaC = np_utils.to_categorical(VaC)\n",
    "print('VaC', VaC.shape)\n",
    "\n",
    "Te = Te.reshape(-1, WS, WS, k, 1)\n",
    "print('Te', Te.shape)\n",
    "TeC = np_utils.to_categorical(TeC)\n",
    "print('TeC', TeC.shape)\n",
    "\n",
    "print('Train Percentage:', TrPercentage)\n",
    "print('Val Percentage:', VaPercentage)\n",
    "print('Test Percentage:', TePercentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hybrid_2D_3D_CNN(WS, k,Num_Classes):\n",
    "    input_layer = Input((WS, WS, k, 1))\n",
    "    conv_layer1 = Conv3D(filters=8, kernel_size=(3, 3, 7), activation='relu')(input_layer)\n",
    "    conv_layer2 = Conv3D(filters=16, kernel_size=(3, 3, 5), activation='relu')(conv_layer1)\n",
    "    conv_layer3 = Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu')(conv_layer2)\n",
    "    ##conv_layer4 = Conv3D(filters=64, kernel_size=(3, 3, 1), activation='relu')(conv_layer3)\n",
    "    ## Conv3D with kernel_size=(3, 3, 1) can be used as well instead to reshape and Con2D.\n",
    "    conv3d_shape = conv_layer3.shape\n",
    "    conv_layer3 = Reshape((conv3d_shape[1], conv3d_shape[2], conv3d_shape[3]*conv3d_shape[4]))(conv_layer3)\n",
    "    conv_layer4 = Conv2D(filters=64, kernel_size=(3,3), activation='relu')(conv_layer3)\n",
    "    flatten_layer = Flatten()(conv_layer4)\n",
    "    dense_layer1 = Dense(units=256, activation = 'relu')(flatten_layer)\n",
    "    dense_layer1 = Dropout(0.4)(dense_layer1)\n",
    "    dense_layer2 = Dense(units = 128, activation = 'relu')(dense_layer1)\n",
    "    dense_layer2 = Dropout(0.4)(dense_layer2)\n",
    "    output_layer = Dense(units = Num_Classes, activation = 'softmax')(dense_layer2)\n",
    "    # Define the Model with Input and Output Layers\n",
    "    model = Model(inputs = input_layer, outputs = output_layer, name='Hybrid_2D_3D')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Fast and Compact 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FC_3DCNN(WS, k,Num_Classes):\n",
    "    input_layer = Input((WS, WS, k, 1))\n",
    "    conv_layer1 = Conv3D(filters=8, kernel_size=(3, 3, 7), activation='relu')(input_layer)\n",
    "    conv_layer2 = Conv3D(filters=16, kernel_size=(3, 3, 5), activation='relu')(conv_layer1)\n",
    "    conv_layer3 = Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu')(conv_layer2)\n",
    "    conv_layer4 = Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu')(conv_layer3)\n",
    "    flatten_layer = Flatten()(conv_layer4)\n",
    "    dense_layer1 = Dense(units=256, activation='relu')(flatten_layer)\n",
    "    dense_layer2 = Dense(units=128, activation='relu')(dense_layer1)\n",
    "    output_layer = Dense(units = Num_Classes, activation='softmax')(dense_layer2)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer, name='FC_3D_CNN')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_encoding(max_len, d_emb):\n",
    "    pos = np.arange(max_len)[:, np.newaxis]\n",
    "    i = np.arange(d_emb)[np.newaxis, :]\n",
    "    angles = pos / np.power(10000, 2 * i / d_emb)\n",
    "    positional_encoding = np.zeros((max_len, d_emb))\n",
    "    positional_encoding[:, ::2] = np.sin(angles[:, ::2])\n",
    "    positional_encoding[:, 1::2] = np.cos(angles[:, 1::2])\n",
    "    return positional_encoding[np.newaxis, ...]\n",
    "\n",
    "class Transformer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads, transformer_layer_depth, d_model, dff, dropout_rate=0.1, layernorm_eps=1e-6, **kwargs):\n",
    "        super(Transformer, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.transformer_layer_depth = transformer_layer_depth\n",
    "        self.d_model = d_model\n",
    "        self.dff = dff\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.layernorm_eps = layernorm_eps\n",
    "\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.dense1 = tf.keras.layers.Dense(dff, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(d_model)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        x = inputs\n",
    "        for i in range(self.transformer_layer_depth):\n",
    "            # Multi-Head Attention\n",
    "            attn_output = self.mha(x, x)\n",
    "            attn_output = self.dropout1(attn_output, training=training)\n",
    "            attn_output = self.layernorm1(x + attn_output)\n",
    "            # Feed Forward Network\n",
    "            ffn_output = self.dense1(attn_output)\n",
    "            ffn_output = self.dense2(ffn_output)\n",
    "            ffn_output = self.dropout2(ffn_output, training=training)\n",
    "            ffn_output = self.layernorm2(attn_output + ffn_output)\n",
    "            x = ffn_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hybrid_ViT(WS, k, Num_Classes):\n",
    "    input_shape = (WS, WS, k)\n",
    "\n",
    "    max_patch_size = min(input_shape[:3])\n",
    "    patch_size = max_patch_size\n",
    "    num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size) * (input_shape[2] // patch_size)\n",
    "    embedding_dim = 64\n",
    "    inputs = Input(shape=input_shape, name='inputs')\n",
    "    x = tf.expand_dims(inputs, axis=1) # add this line\n",
    "    # Create a patch embedding layer\n",
    "    patch_embed = Conv3D(embedding_dim, kernel_size=(1, patch_size, patch_size), strides=(1, patch_size, patch_size), padding='valid', name='patch_embed')(x)\n",
    "\n",
    "    cls_token = tf.Variable(tf.zeros((1, 1, 1, embedding_dim)), name='cls_token')\n",
    "    # Add cls_token to patch embeddings\n",
    "    patch_embed = tf.concat([tf.broadcast_to(cls_token, [tf.shape(patch_embed)[0], 1, 1, 1, embedding_dim]), patch_embed], axis=1)\n",
    "    # Add positional encoding to patch embeddings\n",
    "    pos_encoding = get_positional_encoding(num_patches+1, embedding_dim)\n",
    "\n",
    "    patch_embed = patch_embed + pos_encoding\n",
    "    # Create a Transformer encoder\n",
    "    transformer_layer = Transformer(num_heads=8, transformer_layer_depth=4, d_model=embedding_dim, dff=4 * embedding_dim, name='transformer_layer')(patch_embed)\n",
    "    # Take the first token (cls_token) as output and pass it through a linear layer\n",
    "    output_layer = Dense(Num_Classes, activation='softmax', name='output_layer')(transformer_layer[:, 0, 0, 0])\n",
    "    # Define the model\n",
    "    model = Model(inputs=inputs, outputs=output_layer, name='Custom_ViT')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model_name, Tr, TrC, Va, VaC, Te, TeC, adam, output_dir, HSID, TrPercentage, k, WS, DLM, RDHSI, GT,Num_Classes):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    output_dir = os.path.join(output_dir, \"\") + model_name.__name__\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Calling Custom Model\n",
    "    model = model_name(WS, k, Num_Classes)\n",
    "    model.summary()\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    # Training the model\n",
    "    start = time.time()\n",
    "    history1 = model.fit(x=Tr, y=TrC, batch_size=256, epochs=10, validation_data=(Va, VaC))\n",
    "    end = time.time()\n",
    "    Tr_Time = end - start\n",
    "\n",
    "    # Predicting with the model\n",
    "    start = time.time()\n",
    "    Te_Pred = model.predict(Te)\n",
    "    end = time.time()\n",
    "    Te_Time = end - start\n",
    "\n",
    "    # Other operations (e.g., classification report, CSV file writing, plotting, etc.) remain the same\n",
    "    # Replace \"ViT\" in the filenames with model_name\n",
    "        # Classification Report\n",
    "        ## Prediction and Computing the Accuacy\n",
    "    classification,confusion,oa,each_acc,aa,kappa,target_names = ClassificationReports(TeC, Te_Pred)\n",
    "    print(classification)\n",
    "    ## Writing Results in CSV File\n",
    "    file_name = f\"{HSID}_{TrPercentage}_{k}_{WS}_{DLM}_Classification_Report_{model_name.__name__}.csv\"\n",
    "    CSV_file = CSVResults(os.path.join(output_dir, file_name), classification, confusion, Tr_Time, Te_Time, DL_Time, kappa, oa, aa)\n",
    "  \n",
    "    # Confusion Matrix\n",
    "    cm, annot = Conf_Mat(Te_Pred, TeC, target_names)\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "    sns.heatmap(cm, cmap= \"Spectral\", annot=annot, fmt='', ax=ax, linewidths=0.5)\n",
    "    file_name = f\"{HSID}_{TrPercentage}_{k}_{WS}_{DLM}_Confusion_Matrix_{model_name.__name__}.png\"\n",
    "    plt.savefig(os.path.join(output_dir, file_name), dpi=500)\n",
    "    \n",
    "#     # Ground Truths\n",
    "#     outputs = GT_Plot(RDHSI, GT, model, WS)\n",
    "#     file_name = f\"{HSID}_{TrPercentage}_{k}_{WS}_{DLM}_Ground_Truths_{model_name.__name__}.png\"\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.imshow(outputs, cmap='nipy_spectral')\n",
    "#     plt.axis('off')\n",
    "#     plt.savefig(os.path.join(output_dir, file_name), dpi=500)\n",
    "    \n",
    "    # Loss and Accuracy\n",
    "    plt.figure(figsize=(7,7)) \n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    plt.grid() \n",
    "    plt.plot(history1.history['loss'])\n",
    "    plt.plot(history1.history['val_loss']) \n",
    "    plt.ylabel('Loss') \n",
    "    plt.xlabel('Epochs') \n",
    "    plt.legend(['Tr-Hybrid-ViT','Val-Hybrid-ViT'], loc='upper right')\n",
    "    file_name = f\"{HSID}_{TrPercentage}_{k}_{WS}_{DLM}_loss_curve_{model_name.__name__}.png\"\n",
    "    plt.savefig(os.path.join(output_dir,  file_name))\n",
    "    \n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.ylim(0,1.1)\n",
    "    plt.grid()\n",
    "    plt.plot(history1.history['accuracy'])\n",
    "    plt.plot(history1.history['val_accuracy'])\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(['Tr-{model_name.__name__}','Val-{model_name.__name__}'], loc='lower right')\n",
    "    file_name = f\"{HSID}_{TrPercentage}_{k}_{WS}_{DLM}_acc_curve_{model_name.__name__}.png\"\n",
    "    plt.savefig(os.path.join(output_dir,  file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.broadcast_to), but are not present in its tracked objects:   <tf.Variable 'cls_token:0' shape=(1, 1, 1, 64) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "Model: \"Custom_ViT\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, 9, 9, 15)]   0           []                               \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 1, 9, 9, 15)  0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " patch_embed (Conv3D)           (None, 1, 1, 1, 64)  77824       ['tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLambda  (5,)                0           ['patch_embed[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  ()                  0           ['tf.compat.v1.shape[0][0]']     \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.broadcast_to (TFOpLambda)   (None, 1, 1, 1, 64)  0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 2, 1, 1, 64)  0           ['tf.broadcast_to[0][0]',        \n",
      "                                                                  'patch_embed[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 2, 1, 2, 64)  0          ['tf.concat[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " transformer_layer (Transformer  (None, 2, 1, 2, 64)  166016     ['tf.__operators__.add[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 64)          0           ['transformer_layer[0][0]']      \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, 7)            455         ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 244,295\n",
      "Trainable params: 244,295\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 4s 224ms/step - loss: 1.2971 - accuracy: 0.5154 - val_loss: 0.5525 - val_accuracy: 0.7970\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 0.4570 - accuracy: 0.8302 - val_loss: 0.3751 - val_accuracy: 0.8580\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.2910 - accuracy: 0.8970 - val_loss: 0.2650 - val_accuracy: 0.9391\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.2155 - accuracy: 0.9314 - val_loss: 0.2164 - val_accuracy: 0.9320\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.1547 - accuracy: 0.9550 - val_loss: 0.1949 - val_accuracy: 0.9349\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 0.1122 - accuracy: 0.9675 - val_loss: 0.1677 - val_accuracy: 0.9467\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 0.0823 - accuracy: 0.9787 - val_loss: 0.1658 - val_accuracy: 0.9450\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 1s 126ms/step - loss: 0.0645 - accuracy: 0.9799 - val_loss: 0.1671 - val_accuracy: 0.9432\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0382 - accuracy: 0.9911 - val_loss: 0.1577 - val_accuracy: 0.9491\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 0.0275 - accuracy: 0.9947 - val_loss: 0.1293 - val_accuracy: 0.9621\n",
      "951/951 [==============================] - 6s 6ms/step\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "             blood       0.96      0.98      0.97      2668\n",
      "           ketchup       0.97      0.99      0.98      5259\n",
      "  artificial blood       0.93      0.91      0.92      5774\n",
      "      poster paint       0.98      1.00      0.99      5963\n",
      "tomato concentrate       0.91      0.88      0.89      3541\n",
      "     acrylic paint       0.99      0.98      0.98      7219\n",
      "\n",
      "          accuracy                           0.96     30424\n",
      "         macro avg       0.96      0.96      0.96     30424\n",
      "      weighted avg       0.96      0.96      0.96     30424\n",
      "\n",
      "Model: \"FC_3D_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 9, 9, 15, 1)]     0         \n",
      "                                                                 \n",
      " conv3d (Conv3D)             (None, 7, 7, 9, 8)        512       \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 5, 5, 5, 16)       5776      \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 3, 3, 3, 32)       13856     \n",
      "                                                                 \n",
      " conv3d_3 (Conv3D)           (None, 1, 1, 1, 64)       55360     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               16640     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 125,943\n",
      "Trainable params: 125,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 1.5483 - accuracy: 0.4379 - val_loss: 0.9111 - val_accuracy: 0.6633\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 0.8050 - accuracy: 0.6935 - val_loss: 0.5823 - val_accuracy: 0.7604\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 0.4776 - accuracy: 0.8172 - val_loss: 0.3901 - val_accuracy: 0.8787\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 0.3472 - accuracy: 0.8787 - val_loss: 0.3007 - val_accuracy: 0.8935\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 0.2537 - accuracy: 0.9118 - val_loss: 0.1987 - val_accuracy: 0.9361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 0.1991 - accuracy: 0.9296 - val_loss: 0.1639 - val_accuracy: 0.9450\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 0.1499 - accuracy: 0.9497 - val_loss: 0.1634 - val_accuracy: 0.9361\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 0.1440 - accuracy: 0.9485 - val_loss: 0.1290 - val_accuracy: 0.9544\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 0.1155 - accuracy: 0.9586 - val_loss: 0.1004 - val_accuracy: 0.9639\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 0.0869 - accuracy: 0.9698 - val_loss: 0.0895 - val_accuracy: 0.9669\n",
      "951/951 [==============================] - 7s 7ms/step\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "             blood       0.98      0.96      0.97      2668\n",
      "           ketchup       0.99      0.98      0.99      5259\n",
      "  artificial blood       0.89      0.95      0.92      5774\n",
      "      poster paint       1.00      1.00      1.00      5963\n",
      "tomato concentrate       0.94      0.89      0.91      3541\n",
      "     acrylic paint       0.98      0.96      0.97      7219\n",
      "\n",
      "          accuracy                           0.96     30424\n",
      "         macro avg       0.96      0.96      0.96     30424\n",
      "      weighted avg       0.96      0.96      0.96     30424\n",
      "\n",
      "Model: \"Hybrid_2D_3D\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 9, 9, 15, 1)]     0         \n",
      "                                                                 \n",
      " conv3d_4 (Conv3D)           (None, 7, 7, 9, 8)        512       \n",
      "                                                                 \n",
      " conv3d_5 (Conv3D)           (None, 5, 5, 5, 16)       5776      \n",
      "                                                                 \n",
      " conv3d_6 (Conv3D)           (None, 3, 3, 3, 32)       13856     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 3, 3, 96)          0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, 1, 64)          55360     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 125,943\n",
      "Trainable params: 125,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 1.4525 - accuracy: 0.4231 - val_loss: 0.8527 - val_accuracy: 0.6408\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 0.7648 - accuracy: 0.7024 - val_loss: 0.4643 - val_accuracy: 0.8290\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 0.5009 - accuracy: 0.8107 - val_loss: 0.3360 - val_accuracy: 0.8834\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.3675 - accuracy: 0.8651 - val_loss: 0.2579 - val_accuracy: 0.9166\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.2778 - accuracy: 0.9065 - val_loss: 0.2046 - val_accuracy: 0.9385\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.2143 - accuracy: 0.9302 - val_loss: 0.1480 - val_accuracy: 0.9462\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 0.1738 - accuracy: 0.9414 - val_loss: 0.1316 - val_accuracy: 0.9491\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 1s 147ms/step - loss: 0.1413 - accuracy: 0.9503 - val_loss: 0.1410 - val_accuracy: 0.9521\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 0.1127 - accuracy: 0.9609 - val_loss: 0.1165 - val_accuracy: 0.9574\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 1s 108ms/step - loss: 0.0994 - accuracy: 0.9657 - val_loss: 0.1116 - val_accuracy: 0.9621\n",
      "951/951 [==============================] - 7s 8ms/step\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "             blood       0.96      0.96      0.96      2668\n",
      "           ketchup       0.97      1.00      0.99      5259\n",
      "  artificial blood       0.92      0.91      0.91      5774\n",
      "      poster paint       0.99      1.00      1.00      5963\n",
      "tomato concentrate       0.95      0.86      0.90      3541\n",
      "     acrylic paint       0.96      0.99      0.97      7219\n",
      "\n",
      "          accuracy                           0.96     30424\n",
      "         macro avg       0.96      0.95      0.96     30424\n",
      "      weighted avg       0.96      0.96      0.96     30424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a list of model names\n",
    "model_names = [Hybrid_ViT, FC_3DCNN, Hybrid_2D_3D_CNN] # Add your model names here\n",
    "\n",
    "# Loop over the model names and run train_and_evaluate_model() for each model\n",
    "for model_name in model_names:\n",
    "    train_and_evaluate_model(model_name, Tr, TrC, Va, VaC, Te, TeC, adam, output_dir, HSID, TrPercentage, k, WS, DLM, RDHSI, GT,Num_Classes)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "BloodStain_Identification_V1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
