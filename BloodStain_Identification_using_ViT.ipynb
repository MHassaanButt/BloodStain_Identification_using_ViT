{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impoprting Libraires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "VYFHwxzwT2AB",
    "outputId": "7e7bab91-d1df-470d-d06c-6e2e98513af7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\miniconda3\\envs\\hsi\\Lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import seaborn as sns\n",
    "import spectral\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import (Conv3D,Conv2D, Dense, Dropout, Flatten, Input,\n",
    "                          Reshape,MaxPooling2D)\n",
    "\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import np_utils\n",
    "from sklearn.decomposition import (IncrementalPCA, KernelPCA, PCA, SparsePCA,\n",
    "                                   TruncatedSVD)\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             cohen_kappa_score, confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import (Activation, Lambda, multiply)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from vit_keras import utils, vit\n",
    "import spectral.io.envi as envi\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "from operator import truediv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pnXXoPPeFCLd",
    "outputId": "6213a0ec-4706-496e-f141-0dfb10188bc3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\miniconda3\\envs\\hsi\\Lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "path='../../Datasets/HyperBlood/'\n",
    "\n",
    "HSID = \"E_1\"    ## 'A_1.hdr', 'B_1.hdr', 'C_1.hdr', 'D_1.hdr', 'E_1.hdr', 'E_7.hdr', \n",
    "                ## 'E_21.hdr', 'F_1.hdr.hdr', 'F_1a.hdr', 'F_1s.hdr', 'F_2.hdr', \n",
    "                ## 'F_2k.hdr', 'F_7.hdr', 'F_21.hdr'\n",
    "DLM = \"PCA\"     ## \"PCA\", \"iPCA\", \"SPCA\", \"KPCA\", \"SVD\"\n",
    "WS = 9          ## 9, 11, 13, 15, 17, 19, 21, 23, 25\n",
    "trRatio = 0.05 ##Percentage of Train Samples\n",
    "vrRatio = 0.05 ##Percentage of Validation Samples\n",
    "teRatio = 0.90 ##Percentage of Test Samples\n",
    "k = 15\n",
    "batch_size=256\n",
    "epochs=20\n",
    "adam = legacy.Adam(lr = 0.0001, decay = 1e-05)\n",
    "# output_dir = os.path.join(f\"results/\")\n",
    "output_dir = os.path.join(f\"results/Epochs_{epochs}\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uiIpElfecJRr"
   },
   "outputs": [],
   "source": [
    "## Get HSI Data and Ground Truths\n",
    "## Get HSI Data\n",
    "def get_data(name,remove_bands=True,clean=True, path=path):\n",
    "    \"\"\"\n",
    "    Input: name: name; remove_bands: if True, noisy bands are removed (leaving 113 bands)\n",
    "    clean: if True, remove damaged line\n",
    "    Output: data, wavelenghts as numpy arrays (float32)\n",
    "    \"\"\"\n",
    "    name = convert_name(name)\n",
    "    filename = \"{}data/{}\".format(path,name)\n",
    "    hsimage = envi.open('{}.hdr'.format(filename),'{}.float'.format(filename))\n",
    "    wavs = np.asarray(hsimage.bands.centers) \n",
    "    data = np.asarray(hsimage[:,:,:],dtype=np.float32)\n",
    "    #removal of damaged sensor line\n",
    "    if clean and name!='F_2k':\n",
    "        data = np.delete(data,445,0)\n",
    "    if not remove_bands:\n",
    "        return data,wavs\n",
    "    return data[:,:,get_good_indices(name)],wavs[get_good_indices(name)]\n",
    "\n",
    "## Get Ground Truths\n",
    "def get_anno(name,remove_uncertain_blood=True,clean=True, path=path):\n",
    "    \"\"\"\n",
    "    Returns annotation (GT) for data files as 2D int numpy array\n",
    "    Classes: 0 - background; 1 - blood; 2 - ketchup; 3 - artificial blood; 4 - beetroot juice\n",
    "    5 - poster paint; 6 - tomato concentrate; 7 - acrtylic paint; 8 - uncertain blood;\n",
    "    Input: name: name; clean: if True, remove damaged line; \n",
    "    remove_uncertain_blood: if True, removes class 8 \n",
    "    Output: annotation as numpy 2D array \n",
    "    \"\"\"\n",
    "    name = convert_name(name)\n",
    "    filename = \"{}anno/{}\".format(path,name)\n",
    "    anno = np.load(filename+'.npz')['gt']\n",
    "    #removal of damaged sensor line\n",
    "    if clean and name!='F_2k':\n",
    "        anno = np.delete(anno,445,0)\n",
    "    #remove uncertain blood + technical classes\n",
    "    if remove_uncertain_blood:\n",
    "        anno[anno>7]=0\n",
    "    else:\n",
    "        anno[anno>8]=0\n",
    "    return anno\n",
    "\n",
    "\n",
    "def blood_loader(path, name):\n",
    "    \"\"\"\n",
    "    returns data and annotation, removing classes that are not present in all images\n",
    "    Input: path: data path; name: image name\n",
    "    Output:img: data cube; gt: annotation with correct classes; \n",
    "    rgb_bands: three bands used for rgb visualisation\n",
    "    ignored_labels: labels that should be ignored [0 for background] \n",
    "    label_values: class labels\n",
    "    \"\"\"\n",
    "    img = np.asarray(get_data(name, path=path)[0], dtype='float32')\n",
    "    gt = get_anno(name, path=path).astype('uint8')\n",
    "    # remove beetroot juice (is only on frames images so in our\n",
    "    # classification experiments we removed it from pictures)\n",
    "    gt = np.where(gt == 4, 0, gt)\n",
    "    # renumbering after removing beetroot juice\n",
    "    for element in [5, 6, 7]:\n",
    "        gt = np.where(gt == element, element - 1, gt)\n",
    "    label_values = [\"unclassified\",\n",
    "                    \"blood\",\n",
    "                    \"ketchup\",\n",
    "                    \"artificial blood\",\n",
    "                    \"poster paint\",\n",
    "                    \"tomato concentrate\",\n",
    "                    \"acrylic paint\"]\n",
    "    rgb_bands, ignored_labels = (47, 31, 15), [0]\n",
    "    return img, gt, rgb_bands, ignored_labels, label_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XTwNvyv0CrkW"
   },
   "outputs": [],
   "source": [
    "def convert_name(name):\n",
    "    \"\"\"\n",
    "    Ensures that the name is in the filename format\n",
    "    Parameters: name: name\n",
    "    Output: cleaned name\n",
    "    \"\"\"\n",
    "    name = name.replace('(','_')\n",
    "    name = name.replace(')','')\n",
    "    return name\n",
    "\n",
    "def get_good_indices(name=None):\n",
    "    \"\"\"\n",
    "    Input: name: name\n",
    "    Output: numpy array of good indices         \n",
    "    \"\"\"\n",
    "    name = convert_name(name)\n",
    "    if name!='F_2k':\n",
    "        indices = np.arange(128)\n",
    "        indices = indices[5:-7]\n",
    "    else:\n",
    "        indices = np.arange(116)    \n",
    "    indices=np.delete(indices,[43,44,45])\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7OKY2h4YScVI"
   },
   "outputs": [],
   "source": [
    "## Load HSI Dataset\n",
    "def LoadHSIData(method):\n",
    "    ## List of HSI Dataasets\n",
    "    HSI_list = ['A_1.hdr', 'B_1.hdr', 'C_1.hdr', 'D_1.hdr', 'E_1.hdr', 'E_7.hdr', \n",
    "                'E_21.hdr', 'F_1.hdr.hdr', 'F_1a.hdr', 'F_1s.hdr', 'F_2.hdr', \n",
    "                'F_2k.hdr', 'F_7.hdr', 'F_21.hdr']\n",
    "    for i in range(len(HSI_list)):\n",
    "        file_name = HSI_list[i].split('.')[0]\n",
    "        data_path = os.path.join(os.getcwd(),'../../Datasets/HyperBlood/data'+str(file_name))\n",
    "        # print(data_path)\n",
    "        if os.path.exists(data_path) == False:\n",
    "            # print(\"Data file from %s to %s\" % (HSI_list[i], data_path))\n",
    "            # #urllib.request.urlretrieve(url=HSI_url[i], filename=data_path)\n",
    "            print(str(file_name)+\" is Successfully Found\")\n",
    "        else:\n",
    "            print(str(file_name) + \" already exist\")\n",
    "    data_path = os.path.join(os.getcwd(),'../../Datasets/HyperBlood/data')\n",
    "    data_path1 = os.path.join(os.getcwd(),'../../Datasets/HyperBlood/anno')\n",
    "    if method == 'A_1':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'B_1':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'C_1':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'D_1':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')    \n",
    "    elif method == 'E_1':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'E_7':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'E_21':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'F_1':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'F_1a':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'F_1s':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'F_2':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'F_2k':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')  \n",
    "    elif method == 'F_7':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8')\n",
    "    elif method == 'F_21':\n",
    "        HSI = np.asarray(get_data(method, data_path)[0], dtype='float32')\n",
    "        GT = get_anno(method, data_path1).astype('uint8') \n",
    "    # remove beetroot juice (is only on frames images so in our\n",
    "    # classification experiments we removed it from pictures)\n",
    "    # GT = np.where(GT == 4, 0, GT)\n",
    "    # # renumbering after removing beetroot juice\n",
    "    # for element in [5, 6, 7]:\n",
    "    #     GT = np.where(GT == element, element - 1, GT)\n",
    "    # rgb_bands, ignored_labels = (47, 31, 15), [0]\n",
    "    return HSI, GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UdNQxxanJuQz"
   },
   "outputs": [],
   "source": [
    "## Dimension Reduction\n",
    "def DLMethod(method, HSI, NC = 75):\n",
    "    RHSI = np.reshape(HSI, (-1, HSI.shape[2]))\n",
    "    if method == 'PCA': ## PCA\n",
    "        pca = PCA(n_components = NC, whiten = True)\n",
    "        RHSI = pca.fit_transform(RHSI)\n",
    "        RHSI = np.reshape(RHSI, (HSI.shape[0], HSI.shape[1], NC))\n",
    "    elif method == 'iPCA': ## Incremental PCA\n",
    "        n_batches = 256\n",
    "        inc_pca = IncrementalPCA(n_components = NC)\n",
    "        for X_batch in np.array_split(RHSI, n_batches):\n",
    "            inc_pca.partial_fit(X_batch)\n",
    "        X_ipca = inc_pca.transform(RHSI)\n",
    "        RHSI = np.reshape(X_ipca, (HSI.shape[0], HSI.shape[1], NC))\n",
    "    elif method == 'KPCA': ## Kernel PCA\n",
    "        kpca = KernelPCA(kernel = \"rbf\", n_components = NC, gamma = None, \n",
    "                         fit_inverse_transform = True, random_state = 2019, \n",
    "                         n_jobs=1)\n",
    "        kpca.fit(RHSI)\n",
    "        RHSI = kpca.transform(RHSI)\n",
    "        RHSI = np.reshape(RHSI, (HSI.shape[0], HSI.shape[1], NC))\n",
    "    elif method == 'SPCA': ## Sparse PCA\n",
    "        sparsepca = SparsePCA(n_components = NC, alpha=0.0001, random_state=2019, n_jobs=-1)\n",
    "        sparsepca.fit(RHSI)\n",
    "        RHSI = sparsepca.transform(RHSI)\n",
    "        RHSI = np.reshape(RHSI, (HSI.shape[0], HSI.shape[1], NC))\n",
    "    elif method == 'SVD': ## Singular Value Decomposition\n",
    "        SVD_ = TruncatedSVD(n_components = NC,algorithm = 'randomized', \n",
    "                            random_state = 2019, n_iter=5)\n",
    "        SVD_.fit(RHSI)\n",
    "        RHSI = SVD_.transform(RHSI)\n",
    "        RHSI = np.reshape(RHSI, (HSI.shape[0], HSI.shape[1], NC))\n",
    "    return RHSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CmLBk7cJD40S"
   },
   "outputs": [],
   "source": [
    "## Padding and Spatial Patchs\n",
    "def ZeroPad(HSI, margin = 2):\n",
    "    NHSI = np.zeros((HSI.shape[0] + 2 * margin, HSI.shape[1] + 2* margin, HSI.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    NHSI[x_offset:HSI.shape[0] + x_offset, y_offset:HSI.shape[1] + y_offset, :] = HSI\n",
    "    return NHSI\n",
    "\n",
    "## Compute the Patch to Prepare for Ground Truths\n",
    "def Patch(HSI,height_index,width_index):\n",
    "    height_slice = slice(height_index, height_index+WS)\n",
    "    width_slice = slice(width_index, width_index+WS)\n",
    "    patch = HSI[height_slice, width_slice, :]\n",
    "    return patch\n",
    "    \n",
    "def ImageCubes(HSI, GT, WS = WS, removeZeroLabels = True):\n",
    "    margin = int((WS - 1) / 2)\n",
    "    zeroPaddedX = ZeroPad(HSI, margin = margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((HSI.shape[0] * HSI.shape[1], WS, WS, HSI.shape[2]))\n",
    "    patchesLabels = np.zeros((HSI.shape[0] * HSI.shape[1]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = GT[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
    "        patchesLabels = patchesLabels[patchesLabels>0]\n",
    "        patchesLabels -= 1\n",
    "    return patchesData, patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "c073lR_nEBF7"
   },
   "outputs": [],
   "source": [
    "## Classification Reports\n",
    "def ClassificationReports(TeC, Te_Pred):\n",
    "    Te_Pred = np.argmax(Te_Pred, axis=1)\n",
    "    target_names = [\"blood\",\n",
    "                    \"ketchup\",\n",
    "                    \"artificial blood\",\n",
    "                    \"poster paint\",\n",
    "                    \"tomato concentrate\",\n",
    "                    \"acrylic paint\"]\n",
    "    classification = classification_report(np.argmax(TeC, axis=1), Te_Pred, target_names = target_names)\n",
    "    oa = accuracy_score(np.argmax(TeC, axis=1), Te_Pred)\n",
    "    confusion = confusion_matrix(np.argmax(TeC, axis=1), Te_Pred)\n",
    "    counter = confusion.shape[0]\n",
    "    list_diag = np.diag(confusion)\n",
    "    list_raw_sum = np.sum(confusion, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    aa = np.mean(each_acc)\n",
    "    kappa = cohen_kappa_score(np.argmax(TeC, axis=1), Te_Pred)\n",
    "    return classification, confusion, oa*100, each_acc*100, aa*100, kappa*100, target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "a0e_9RypEiH4"
   },
   "outputs": [],
   "source": [
    "## Writing Classification Results\n",
    "def CSVResults(file_name, classification, confusion, Tr_Time, Te_Time, DL_Time, kappa, oa, aa):\n",
    "    classification = str(classification)\n",
    "    confusion = str(confusion)\n",
    "    with open(file_name, 'w') as CSV_file:\n",
    "        \n",
    "        CSV_file.write('{} Tr_Time'.format(Tr_Time))\n",
    "        CSV_file.write('\\n')\n",
    "        CSV_file.write('{} Te_Time'.format(Te_Time))\n",
    "        CSV_file.write('\\n')\n",
    "        CSV_file.write('{} DL_Time'.format(DL_Time))\n",
    "        CSV_file.write('\\n')\n",
    "        CSV_file.write('{} Kappa accuracy (%)'.format(kappa))\n",
    "        CSV_file.write('\\n')\n",
    "        CSV_file.write('{} Overall accuracy (%)'.format(oa))\n",
    "        CSV_file.write('\\n')\n",
    "        CSV_file.write('{} Average accuracy (%)'.format(aa))\n",
    "        CSV_file.write('\\n')\n",
    "        CSV_file.write('\\n')\n",
    "        CSV_file.write('{}'.format(classification))\n",
    "        CSV_file.write('\\n')\n",
    "        CSV_file.write('{}'.format(confusion))\n",
    "        return CSV_file\n",
    "    \n",
    "## Plot Ground Truths \n",
    "def GT_Plot(RDHSI, GT, model, WS):\n",
    "    height, width = np.shape(GT)\n",
    "    RDHSI = ZeroPad(RDHSI, WS//2) ## Zero Padding\n",
    "    ## Calculate the predicted Ground Truths\n",
    "    outputs = np.zeros((height, width))\n",
    "    for AA in range(height):\n",
    "        for BB in range(width):\n",
    "            \n",
    "            target = int(GT[AA,BB])\n",
    "            if target == 0:\n",
    "                continue\n",
    "            else :\n",
    "                image_patch = Patch(RDHSI,AA,BB)\n",
    "                X_test_image = image_patch.reshape(1,image_patch.shape[0],\n",
    "                                             image_patch.shape[1],\n",
    "                                             image_patch.shape[2],\n",
    "                                             1).astype('float32')\n",
    "                prediction = (model.predict(X_test_image))\n",
    "                prediction = np.argmax(prediction, axis=1)\n",
    "                outputs[AA][BB] = prediction+1\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tPIeFTGkEw08"
   },
   "outputs": [],
   "source": [
    "## Plot and Save Confusion Matrix\n",
    "def Conf_Mat(Te_Pred, TeC, target_names):\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "    Te_Pred = np.argmax(Te_Pred, axis=1)\n",
    "    confusion = confusion_matrix(np.argmax(TeC, axis=1), Te_Pred, labels=np.unique(np.argmax(TeC, axis=1)))\n",
    "    cm_sum = np.sum(confusion, axis=1, keepdims=True)\n",
    "    cm_perc = confusion / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(confusion).astype(str)\n",
    "    nrows, ncols = confusion.shape\n",
    "    for l in range(nrows):\n",
    "        for m in range(ncols):\n",
    "            c = confusion[l, m]\n",
    "            p = cm_perc[l, m]\n",
    "            if l == m:\n",
    "                s = cm_sum[l]\n",
    "                annot[l, m] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[l, m] = ''\n",
    "            else:\n",
    "                annot[l, m] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(confusion, index=np.unique(target_names), columns=np.unique(target_names))\n",
    "    return cm, annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_1 is Successfully Found\n",
      "B_1 is Successfully Found\n",
      "C_1 is Successfully Found\n",
      "D_1 is Successfully Found\n",
      "E_1 is Successfully Found\n",
      "E_7 is Successfully Found\n",
      "E_21 is Successfully Found\n",
      "F_1 is Successfully Found\n",
      "F_1a is Successfully Found\n",
      "F_1s is Successfully Found\n",
      "F_2 is Successfully Found\n",
      "F_2k is Successfully Found\n",
      "F_7 is Successfully Found\n",
      "F_21 is Successfully Found\n",
      "# of Dimensions 15\n",
      "Shape of HSI (519, 696, 113)\n",
      "Shape of GT (519, 696)\n",
      "Name of Classes [0 1 2 3 5 6 7]\n",
      "# of Classes 7\n"
     ]
    }
   ],
   "source": [
    "HSI, GT = LoadHSIData(HSID)\n",
    "\n",
    "print(\"# of Dimensions\", k)          ## Dimensions\n",
    "print(\"Shape of HSI\", HSI.shape)\n",
    "print(\"Shape of GT\", GT.shape)\n",
    "# UC = np.unique(label_values)\n",
    "UC = np.unique(GT)\n",
    "print(\"Name of Classes\", UC)\n",
    "Num_Classes = len(UC)\n",
    "print(\"# of Classes\", Num_Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yZ4HQLx4GLW_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DL_Time 1.2447617053985596\n"
     ]
    }
   ],
   "source": [
    "## Reduce the Dimensionality\n",
    "start = time.time()\n",
    "RDHSI = DLMethod(DLM, HSI, NC = k)\n",
    "end = time.time()\n",
    "DL_Time = end - start\n",
    "print(\"DL_Time\",DL_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ODRw_s36KV5V",
    "outputId": "00fe46a1-38af-4ad1-d491-1cabfb7fc854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of HSI (33804, 9, 9, 15)\n",
      "Shape of GT (33804,)\n"
     ]
    }
   ],
   "source": [
    "## Create Image Cubes for Model Building\n",
    "CRDHSI, CGT = ImageCubes(RDHSI, GT, WS = WS)\n",
    "print(\"Shape of HSI\", CRDHSI.shape)\n",
    "print(\"Shape of GT\", CGT.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WKGHTFPLFZzv",
    "outputId": "3c0607f2-b4fa-4348-88df-df7426a395f1"
   },
   "source": [
    "## Split Train and Test sets\n",
    "Tr, Te, TrC, TeC = TrTeSplit(CRDHSI, CGT, TeRatio)\n",
    "## Split Train and Validation\n",
    "Tr, Va, TrC, VaC = TrTeSplit(Tr, TrC, VeRatio)\n",
    "## Reshape Train, Validation, and Test sets\n",
    "Tr = Tr.reshape(-1, WS, WS, k, 1)\n",
    "print('Tr', Tr.shape)\n",
    "TrC = np_utils.to_categorical(TrC)\n",
    "print('TrC', TrC.shape)\n",
    "Va = Va.reshape(-1, WS, WS, k, 1)\n",
    "print('Va', Va.shape)\n",
    "VaC = np_utils.to_categorical(VaC)\n",
    "print('VaC', VaC.shape)\n",
    "Te = Te.reshape(-1, WS, WS, k, 1)\n",
    "print('Te', Te.shape)\n",
    "TeC = np_utils.to_categorical(TeC)\n",
    "print('TeC', TeC.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tr (1690, 9, 9, 15, 1)\n",
      "TrC (1690, 7)\n",
      "Va (1690, 9, 9, 15, 1)\n",
      "VaC (1690, 7)\n",
      "Te (30424, 9, 9, 15, 1)\n",
      "TeC (30424, 7)\n"
     ]
    }
   ],
   "source": [
    "def TrTeSplit(HSI, GT, trRatio, vrRatio, teRatio, randomState=345):\n",
    "    # Split into train and test sets\n",
    "    Tr, Te, TrC, TeC = train_test_split(HSI, GT, test_size=teRatio,\n",
    "                                        random_state=randomState, stratify=GT)\n",
    "    # Calculate the validation ratio based on the updated test and train ratios\n",
    "    totalTrRatio = trRatio + vrRatio\n",
    "    new_vrRatio = vrRatio / totalTrRatio\n",
    "    # Split train set into train and validation sets\n",
    "    Tr, Va, TrC, VaC = train_test_split(Tr, TrC, test_size=new_vrRatio,\n",
    "                                        random_state=randomState, stratify=TrC)\n",
    "\n",
    "    return Tr, Va, Te, TrC, VaC, TeC\n",
    "\n",
    "# trRatio = 0.11 \n",
    "# vrRatio = 0.11 \n",
    "# teRatio = 0.78 \n",
    "Tr, Va, Te, TrC, VaC, TeC = TrTeSplit(CRDHSI, CGT, trRatio, vrRatio, teRatio)\n",
    "\n",
    "# Reshape train, validation, and test sets\n",
    "Tr = Tr.reshape(-1, WS, WS, k, 1)\n",
    "print('Tr', Tr.shape)\n",
    "TrC = np_utils.to_categorical(TrC)\n",
    "print('TrC', TrC.shape)\n",
    "\n",
    "Va = Va.reshape(-1, WS, WS, k, 1)\n",
    "print('Va', Va.shape)\n",
    "VaC = np_utils.to_categorical(VaC)\n",
    "print('VaC', VaC.shape)\n",
    "\n",
    "Te = Te.reshape(-1, WS, WS, k, 1)\n",
    "print('Te', Te.shape)\n",
    "TeC = np_utils.to_categorical(TeC)\n",
    "print('TeC', TeC.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_2D(WS, k,Num_Classes):\n",
    "    input_layer = Input((WS, WS, k))\n",
    "    conv_layer1 = Conv2D(filters=8, kernel_size=(3, 3), activation='relu')(input_layer)\n",
    "    conv_layer2 = Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(conv_layer1)\n",
    "    conv_layer3 = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(conv_layer2)\n",
    "    conv_layer4 = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(conv_layer3)\n",
    "    flatten_layer = Flatten()(conv_layer4)\n",
    "    dense_layer1 = Dense(units=256, activation='relu')(flatten_layer)\n",
    "    dense_layer1 = Dropout(0.4)(dense_layer1)\n",
    "    dense_layer2 = Dense(units=128, activation='relu')(dense_layer1)\n",
    "    dense_layer2 = Dropout(0.4)(dense_layer2)\n",
    "    output_layer = Dense(units=Num_Classes, activation='softmax')(dense_layer2)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer, name='2D_CNN')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D inception Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inception_Net_2D(WS, k,Num_Classes):\n",
    "    \n",
    "    input_img = Input(shape=(WS, WS, k))\n",
    "    ## Block 1\n",
    "    layer_1 = Conv2D(30, (1, 1), padding = 'same', activation = 'relu')(input_img)\n",
    "    layer_1 = Conv2D(20, (1, 1), padding = 'same', activation = 'relu')(layer_1)\n",
    "    layer_1 = Conv2D(10, (3, 3), padding = 'same', activation = 'relu')(layer_1)\n",
    "    ## Block 2\n",
    "    layer_2 = Conv2D(40, (1, 1), padding = 'same', activation = 'relu')(input_img)\n",
    "    layer_2 = Conv2D(20, (1, 1), padding = 'same', activation = 'relu')(layer_2)\n",
    "    layer_2 = Conv2D(10, (5, 5), padding = 'same', activation = 'relu')(layer_2)\n",
    "    ## Block 3\n",
    "    layer_3 = MaxPooling2D((3, 3), strides = (1, 1), padding = 'same')(input_img)\n",
    "    layer_3 = Conv2D(20, (1, 1), padding = 'same', activation = 'relu')(layer_3)\n",
    "    layer_3 = Conv2D(10, (1, 1), padding = 'same', activation = 'relu')(layer_3)\n",
    "    ## Concatination\n",
    "    mid_1 = keras.layers.concatenate([layer_1, layer_2, layer_3], axis = 3)\n",
    "    ## Convolution\n",
    "    layer_4 = Conv2D(128, (1, 1), activation = 'relu')(mid_1)\n",
    "    ## Classification Module\n",
    "    flat_1 = Flatten()(layer_4)\n",
    "    dense_1 = Dense(1200, activation = 'relu')(flat_1)\n",
    "    dense_2 = Dense(600, activation = 'relu')(dense_1)\n",
    "    dense_3 = Dense(150, activation = 'relu')(dense_2)\n",
    "    output = Dense(Num_Classes, activation = 'softmax')(dense_3)\n",
    "    ## Medel \n",
    "    model = Model([input_img], output, name='2D_Inception_Net')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D inception Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inception_Net_3D(WS, k,Num_Classes):\n",
    "    input_img = Input(shape=(WS, WS, k, 1))\n",
    "    ## Block 1\n",
    "    layer_1 = Conv3D(30, (5, 5, 7), activation='relu')(input_img)\n",
    "    layer_1 = Conv3D(20, (3, 3, 5), activation='relu')(layer_1)\n",
    "    layer_1 = Conv3D(10, (3, 3, 3), activation='relu')(layer_1)\n",
    "    ## Block 2\n",
    "    layer_2 = Conv3D(40, (5, 5, 7), activation='relu')(input_img)\n",
    "    layer_2 = Conv3D(20, (3, 3, 5), activation='relu')(layer_2)\n",
    "    layer_2 = Conv3D(10, (3, 3, 3), activation='relu')(layer_2)\n",
    "    ## Block 3\n",
    "    layer_3 = Conv3D(60, (5, 5, 7), activation='relu')(input_img)\n",
    "    layer_3 = Conv3D(30, (3, 3, 5), activation='relu')(layer_3)\n",
    "    layer_3 = Conv3D(10, (3, 3, 3), activation='relu')(layer_3)\n",
    "    ## Concatination\n",
    "    mid_1 = keras.layers.concatenate([layer_1, layer_2, layer_3], axis = 3)\n",
    "    ## Convolution\n",
    "    layer_4 = Conv3D(128, (1, 1, 1), activation = 'relu')(mid_1)\n",
    "    ## Classification Module\n",
    "    flat_1 = Flatten()(layer_4)\n",
    "    dense_1 = Dense(512, activation='relu')(flat_1)\n",
    "    dense_1 = Dropout(0.4)(dense_1)\n",
    "    dense_2 = Dense(128, activation='relu')(dense_1)\n",
    "    dense_2 = Dropout(0.4)(dense_2)\n",
    "    dense_3 = Dense(64, activation='relu')(dense_2)\n",
    "    dense_3 = Dropout(0.4)(dense_3)\n",
    "    output = Dense(Num_Classes, activation='softmax')(dense_3)\n",
    "    model = Model([input_img], output, name='3D_Inception_Net')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Inception Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hybrid_Inception_Net(WS, k,Num_Classes):\n",
    "    input_img = Input(shape=(WS, WS, k, 1))\n",
    "    ## Block 1\n",
    "    layer_1 = Conv3D(30, (5, 5, 7), activation='relu')(input_img)\n",
    "    layer_1 = Conv3D(20, (3, 3, 5), activation='relu')(layer_1)\n",
    "    layer_1 = Conv3D(10, (3, 3, 3), activation='relu')(layer_1)\n",
    "    layer_1_shape = layer_1.shape\n",
    "    ## 2D Structure\n",
    "    layer_1 = Reshape((layer_1_shape[1], layer_1_shape[2], layer_1_shape[3]*layer_1_shape[4]))(layer_1)\n",
    "    layer_1 = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_1)\n",
    "    layer_1 = Conv2D(filters = 16, kernel_size = (1, 1), activation = 'relu')(layer_1)\n",
    "    layer_1 = Conv2D(filters = 32, kernel_size = (1, 1), activation = 'relu')(layer_1)\n",
    "    layer_1 = Conv2D(filters = 64, kernel_size = (1, 1), activation = 'relu')(layer_1)\n",
    "    ## Block 2\n",
    "    layer_2 = Conv3D(40, (5, 5, 7), activation = 'relu')(input_img)\n",
    "    layer_2 = Conv3D(20, (3, 3, 5), activation = 'relu')(layer_2)\n",
    "    layer_2 = Conv3D(10, (3, 3, 3), activation = 'relu')(layer_2)\n",
    "    ## 2D Structure\n",
    "    layer_2_shape = layer_2.shape\n",
    "    layer_2 = Reshape((layer_2_shape[1], layer_2_shape[2], layer_2_shape[3]*layer_2_shape[4]))(layer_2)\n",
    "    layer_2 = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_2)\n",
    "    layer_2 = Conv2D(filters = 16, kernel_size = (1, 1), activation = 'relu')(layer_2)\n",
    "    layer_2 = Conv2D(filters = 32, kernel_size = (1, 1), activation = 'relu')(layer_2)\n",
    "    layer_2 = Conv2D(filters = 64, kernel_size = (1, 1), activation = 'relu')(layer_2)\n",
    "    ## Block 3\n",
    "    layer_3 = Conv3D(60, (5, 5, 7), activation='relu')(input_img)\n",
    "    layer_3 = Conv3D(30, (3, 3, 5), activation='relu')(layer_3)\n",
    "    layer_3 = Conv3D(10, (3, 3, 3), activation='relu')(layer_3)\n",
    "    ## 2D Structure\n",
    "    layer_3_shape = layer_3.shape\n",
    "    layer_3 = Reshape((layer_3_shape[1], layer_3_shape[2], layer_3_shape[3]*layer_3_shape[4]))(layer_3)\n",
    "    layer_3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_3)\n",
    "    layer_3 = Conv2D(filters = 16, kernel_size=(1, 1), activation = 'relu')(layer_3)\n",
    "    layer_3 = Conv2D(filters = 32, kernel_size=(1, 1), activation = 'relu')(layer_3)\n",
    "    layer_3 = Conv2D(filters = 64, kernel_size = (1, 1), activation = 'relu')(layer_3)\n",
    "    ## Concatinate \n",
    "    mid_1 = keras.layers.concatenate([layer_1, layer_2, layer_3], axis = 3)\n",
    "    ## Convolution\n",
    "    layer_4 = Conv2D(filters = 128, kernel_size = (1, 1), activation = 'relu')(mid_1)\n",
    "    ## Classification Model\n",
    "    flat_1 = Flatten()(layer_4)\n",
    "    dense_1 = Dense(512, activation='relu')(flat_1)\n",
    "    dense_1 = Dropout(0.4)(dense_1)\n",
    "    dense_2 = Dense(128, activation='relu')(dense_1)\n",
    "    dense_2 = Dropout(0.4)(dense_2)\n",
    "    dense_3 = Dense(64, activation='relu')(dense_2)\n",
    "    dense_3 = Dropout(0.4)(dense_3)\n",
    "    output = Dense(Num_Classes, activation='softmax')(dense_3)\n",
    "    ## Medel \n",
    "    model = Model([input_img], output, name='Hybrid_Inception_Net')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hybrid_2D_3D_CNN(WS, k,Num_Classes):\n",
    "    input_layer = Input((WS, WS, k, 1))\n",
    "    conv_layer1 = Conv3D(filters=8, kernel_size=(3, 3, 7), activation='relu')(input_layer)\n",
    "    conv_layer2 = Conv3D(filters=16, kernel_size=(3, 3, 5), activation='relu')(conv_layer1)\n",
    "    conv_layer3 = Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu')(conv_layer2)\n",
    "    ##conv_layer4 = Conv3D(filters=64, kernel_size=(3, 3, 1), activation='relu')(conv_layer3)\n",
    "    ## Conv3D with kernel_size=(3, 3, 1) can be used as well instead to reshape and Con2D.\n",
    "    conv3d_shape = conv_layer3.shape\n",
    "    conv_layer3 = Reshape((conv3d_shape[1], conv3d_shape[2], conv3d_shape[3]*conv3d_shape[4]))(conv_layer3)\n",
    "    conv_layer4 = Conv2D(filters=64, kernel_size=(3,3), activation='relu')(conv_layer3)\n",
    "    flatten_layer = Flatten()(conv_layer4)\n",
    "    dense_layer1 = Dense(units=256, activation = 'relu')(flatten_layer)\n",
    "    dense_layer1 = Dropout(0.4)(dense_layer1)\n",
    "    dense_layer2 = Dense(units = 128, activation = 'relu')(dense_layer1)\n",
    "    dense_layer2 = Dropout(0.4)(dense_layer2)\n",
    "    output_layer = Dense(units = Num_Classes, activation = 'softmax')(dense_layer2)\n",
    "    # Define the Model with Input and Output Layers\n",
    "    model = Model(inputs = input_layer, outputs = output_layer, name='Hybrid_2D_3D')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Fast and Compact 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FC_3DCNN(WS, k,Num_Classes):\n",
    "    input_layer = Input((WS, WS, k, 1))\n",
    "    conv_layer1 = Conv3D(filters=8, kernel_size=(3, 3, 7), activation='relu')(input_layer)\n",
    "    conv_layer2 = Conv3D(filters=16, kernel_size=(3, 3, 5), activation='relu')(conv_layer1)\n",
    "    conv_layer3 = Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu')(conv_layer2)\n",
    "    conv_layer4 = Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu')(conv_layer3)\n",
    "    flatten_layer = Flatten()(conv_layer4)\n",
    "    dense_layer1 = Dense(units=256, activation='relu')(flatten_layer)\n",
    "    dense_layer2 = Dense(units=128, activation='relu')(dense_layer1)\n",
    "    output_layer = Dense(units = Num_Classes, activation='softmax')(dense_layer2)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer, name='FC_3D_CNN')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_encoding(max_len, d_emb):\n",
    "    pos = np.arange(max_len)[:, np.newaxis]\n",
    "    i = np.arange(d_emb)[np.newaxis, :]\n",
    "    angles = pos / np.power(10000, 2 * i / d_emb)\n",
    "    positional_encoding = np.zeros((max_len, d_emb))\n",
    "    positional_encoding[:, ::2] = np.sin(angles[:, ::2])\n",
    "    positional_encoding[:, 1::2] = np.cos(angles[:, 1::2])\n",
    "    return positional_encoding[np.newaxis, ...]\n",
    "\n",
    "class Transformer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads, transformer_layer_depth, d_model, dff, dropout_rate=0.1, layernorm_eps=1e-6, **kwargs):\n",
    "        super(Transformer, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.transformer_layer_depth = transformer_layer_depth\n",
    "        self.d_model = d_model\n",
    "        self.dff = dff\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.layernorm_eps = layernorm_eps\n",
    "\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.dense1 = tf.keras.layers.Dense(dff, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(d_model)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        x = inputs\n",
    "        for i in range(self.transformer_layer_depth):\n",
    "            # Multi-Head Attention\n",
    "            attn_output = self.mha(x, x)\n",
    "            attn_output = self.dropout1(attn_output, training=training)\n",
    "            attn_output = self.layernorm1(x + attn_output)\n",
    "            # Feed Forward Network\n",
    "            ffn_output = self.dense1(attn_output)\n",
    "            ffn_output = self.dense2(ffn_output)\n",
    "            ffn_output = self.dropout2(ffn_output, training=training)\n",
    "            ffn_output = self.layernorm2(attn_output + ffn_output)\n",
    "            x = ffn_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def Hybrid_ViT(WS, k, Num_Classes):\n",
    "    input_shape = (WS, WS, k)\n",
    "\n",
    "    max_patch_size = min(input_shape[:3])\n",
    "    patch_size = max_patch_size\n",
    "    num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size) * (input_shape[2] // patch_size)\n",
    "    embedding_dim = 64\n",
    "    inputs = Input(shape=input_shape, name='inputs')\n",
    "    x = tf.expand_dims(inputs, axis=1) # add this line\n",
    "    # Create a patch embedding layer\n",
    "    patch_embed = Conv3D(embedding_dim, kernel_size=(1, patch_size, patch_size), strides=(1, patch_size, patch_size), padding='valid', name='patch_embed')(x)\n",
    "\n",
    "    cls_token = tf.Variable(tf.zeros((1, 1, 1, embedding_dim)), name='cls_token')\n",
    "    # Add cls_token to patch embeddings\n",
    "    patch_embed = tf.concat([tf.broadcast_to(cls_token, [tf.shape(patch_embed)[0], 1, 1, 1, embedding_dim]), patch_embed], axis=1)\n",
    "    # Add positional encoding to patch embeddings\n",
    "    pos_encoding = get_positional_encoding(num_patches+1, embedding_dim)\n",
    "\n",
    "    patch_embed = patch_embed + pos_encoding\n",
    "    # Create a Transformer encoder\n",
    "    transformer_layer = Transformer(num_heads=8, transformer_layer_depth=4, d_model=embedding_dim, dff=4 * embedding_dim, name='transformer_layer')(patch_embed)\n",
    "    # Take the first token (cls_token) as output and pass it through a linear layer\n",
    "    output_layer = Dense(Num_Classes, activation='softmax', name='output_layer')(transformer_layer[:, 0, 0, 0])\n",
    "    # Define the model\n",
    "    model = Model(inputs=inputs, outputs=output_layer, name='Hybrid_ViT')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hybrid_ViT(WS, k, Num_Classes, num_transformer_layers=4, num_heads=8, dff=4*64, dropout_rate=0.1, layernorm_eps=1e-3):\n",
    "    input_shape = (WS, WS, k)\n",
    "\n",
    "    max_patch_size = min(input_shape[:3])\n",
    "    patch_size = max_patch_size\n",
    "    num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size) * (input_shape[2] // patch_size)\n",
    "    embedding_dim = 64\n",
    "    inputs = Input(shape=input_shape, name='inputs')\n",
    "    x = tf.expand_dims(inputs, axis=1) # add this line\n",
    "    # Create a patch embedding layer\n",
    "    patch_embed = Conv3D(embedding_dim, kernel_size=(1, patch_size, patch_size), strides=(1, patch_size, patch_size), padding='valid', name='patch_embed')(x)\n",
    "\n",
    "    cls_token = tf.Variable(tf.zeros((1, 1, 1, embedding_dim)), name='cls_token')\n",
    "    # Add cls_token to patch embeddings\n",
    "    patch_embed = tf.concat([tf.broadcast_to(cls_token, [tf.shape(patch_embed)[0], 1, 1, 1, embedding_dim]), patch_embed], axis=1)\n",
    "    # Add positional encoding to patch embeddings\n",
    "    pos_encoding = get_positional_encoding(num_patches+1, embedding_dim)\n",
    "\n",
    "    patch_embed = patch_embed + pos_encoding\n",
    "    # Create a Transformer encoder\n",
    "    for i in range(num_transformer_layers):\n",
    "        if i == 0:\n",
    "            transformer_layer = Transformer(num_heads=num_heads, transformer_layer_depth=1, d_model=embedding_dim, dff=dff, name=f'transformer_layer_{i}')(patch_embed)\n",
    "        else:\n",
    "            transformer_layer = Transformer(num_heads=num_heads, transformer_layer_depth=1, d_model=embedding_dim, dff=dff, name=f'transformer_layer_{i}')(transformer_layer)\n",
    "\n",
    "    # Use cross-attention between the patch embeddings and a separate set of learnable embeddings\n",
    "    q = Dense(embedding_dim)(transformer_layer[:, 0, 0, 0])\n",
    "    k = Dense(embedding_dim)(patch_embed[:, 1:, :, :, :])\n",
    "    v = patch_embed[:, 1:, :, :, :]\n",
    "    cross_attn_output = tf.matmul(q[:, tf.newaxis, :], k, transpose_b=True)\n",
    "    cross_attn_output = cross_attn_output / tf.math.sqrt(tf.cast(embedding_dim, dtype=tf.float32))\n",
    "    cross_attn_output = tf.nn.softmax(cross_attn_output, axis=-1)\n",
    "    cross_attn_output = tf.matmul(cross_attn_output, v)\n",
    "    # Concatenate cls_token and cross-attention output\n",
    "    output_layer = tf.concat([transformer_layer[:, 0, 0, 0], cross_attn_output[:, 0, 0, 0]], axis=-1)\n",
    "    # Add a few dense layers and a final softmax layer\n",
    "    output_layer = Dense(dff, activation='relu')(output_layer)\n",
    "    output_layer = Dense(dff, activation='relu')(output_layer)\n",
    "    output_layer = Dense(Num_Classes, activation='softmax', name='output_layer')(output_layer)\n",
    "    # Define the model\n",
    "    model = Model(inputs=inputs, outputs=output_layer, name='Hybrid_ViT')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model_name, Tr, TrC, Va, VaC, Te, TeC, adam, output_dir, HSID, teRatio, k, WS, DLM, RDHSI, GT,Num_Classes,batch_size,epochs):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    output_dir = os.path.join(output_dir, \"\") + model_name.__name__\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Calling Custom Model\n",
    "    model = model_name(WS, k, Num_Classes)\n",
    "    model.summary()\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    # Training the model\n",
    "    start = time.time()\n",
    "    history = model.fit(x=Tr, y=TrC, batch_size=batch_size, epochs=epochs, validation_data=(Va, VaC))\n",
    "    end = time.time()\n",
    "    Tr_Time = end - start\n",
    "\n",
    "    # Predicting with the model\n",
    "    start = time.time()\n",
    "    Te_Pred = model.predict(Te)\n",
    "    end = time.time()\n",
    "    Te_Time = end - start\n",
    "\n",
    "     # Classification Report\n",
    "    classification,confusion,oa,each_acc,aa,kappa,target_names = ClassificationReports(TeC, Te_Pred)\n",
    "    print(classification)\n",
    "    ## Writing Results in CSV File\n",
    "    file_name = f\"{HSID}_{teRatio}_{k}_{WS}_{DLM}_Classification_Report_{model_name.__name__}.csv\"\n",
    "    CSV_file = CSVResults(os.path.join(output_dir, file_name), classification, confusion, Tr_Time, Te_Time, DL_Time, kappa, oa, aa)\n",
    "  \n",
    "    # Confusion Matrix\n",
    "#     cm, annot = Conf_Mat(Te_Pred, TeC, target_names)\n",
    "#     cm.index.name = 'Actual'\n",
    "#     cm.columns.name = 'Predicted'\n",
    "#     fig, ax = plt.subplots(figsize=(15,15))\n",
    "#     sns.heatmap(cm, cmap= \"Spectral\", annot=annot, fmt='', ax=ax, linewidths=0.5)\n",
    "#     file_name = f\"{HSID}_{teRatio}_{k}_{WS}_{DLM}_Confusion_Matrix_{model_name.__name__}.png\"\n",
    "#     plt.savefig(os.path.join(output_dir, file_name), dpi=500)\n",
    "    \n",
    "#     # Ground Truths\n",
    "#     outputs = GT_Plot(RDHSI, GT, model, WS)\n",
    "#     file_name = f\"{HSID}_{teRatio}_{k}_{WS}_{DLM}_Ground_Truths_{model_name.__name__}.png\"\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.imshow(outputs, cmap='nipy_spectral')\n",
    "#     plt.axis('off')\n",
    "#     plt.savefig(os.path.join(output_dir, file_name), dpi=500)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"2D_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 9, 9, 15)]        0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 7, 7, 8)           1088      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 5, 5, 16)          1168      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 32)          4640      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 1, 1, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 75,831\n",
      "Trainable params: 75,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 48ms/step - loss: 1.9126 - accuracy: 0.1882 - val_loss: 1.8894 - val_accuracy: 0.2385\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.8730 - accuracy: 0.2391 - val_loss: 1.8439 - val_accuracy: 0.2426\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.8298 - accuracy: 0.2497 - val_loss: 1.7847 - val_accuracy: 0.2391\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.7701 - accuracy: 0.2509 - val_loss: 1.7128 - val_accuracy: 0.2373\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.6980 - accuracy: 0.2710 - val_loss: 1.6384 - val_accuracy: 0.2373\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.6393 - accuracy: 0.2621 - val_loss: 1.5764 - val_accuracy: 0.2373\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.5878 - accuracy: 0.2722 - val_loss: 1.5233 - val_accuracy: 0.2503\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.5375 - accuracy: 0.3225 - val_loss: 1.4670 - val_accuracy: 0.3905\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.4785 - accuracy: 0.3911 - val_loss: 1.4044 - val_accuracy: 0.5515\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.4281 - accuracy: 0.4296 - val_loss: 1.3310 - val_accuracy: 0.6089\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.3543 - accuracy: 0.4923 - val_loss: 1.2442 - val_accuracy: 0.6154\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.2734 - accuracy: 0.5396 - val_loss: 1.1463 - val_accuracy: 0.6195\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.1877 - accuracy: 0.5604 - val_loss: 1.0473 - val_accuracy: 0.6201\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.0914 - accuracy: 0.5840 - val_loss: 0.9584 - val_accuracy: 0.6284\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.0288 - accuracy: 0.6006 - val_loss: 0.8892 - val_accuracy: 0.6373\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9711 - accuracy: 0.6101 - val_loss: 0.8335 - val_accuracy: 0.6467\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.9200 - accuracy: 0.6296 - val_loss: 0.7899 - val_accuracy: 0.6651\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.8582 - accuracy: 0.6550 - val_loss: 0.7533 - val_accuracy: 0.6846\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.8193 - accuracy: 0.6840 - val_loss: 0.7213 - val_accuracy: 0.7006\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7829 - accuracy: 0.6828 - val_loss: 0.6903 - val_accuracy: 0.7059\n",
      "951/951 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\miniconda3\\envs\\hsi\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hassa\\miniconda3\\envs\\hsi\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hassa\\miniconda3\\envs\\hsi\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "             blood       0.00      0.00      0.00      2668\n",
      "           ketchup       0.60      0.96      0.74      5259\n",
      "  artificial blood       0.46      0.59      0.52      5774\n",
      "      poster paint       0.89      0.99      0.93      5963\n",
      "tomato concentrate       0.65      0.03      0.05      3541\n",
      "     acrylic paint       0.87      0.92      0.89      7219\n",
      "\n",
      "          accuracy                           0.69     30424\n",
      "         macro avg       0.58      0.58      0.52     30424\n",
      "      weighted avg       0.64      0.69      0.63     30424\n",
      "\n",
      "Model: \"2D_Inception_Net\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 9, 9, 15)]   0           []                               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 9, 9, 30)     480         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 9, 9, 40)     640         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 9, 9, 15)     0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 9, 9, 20)     620         ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 9, 9, 20)     820         ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 9, 9, 20)     320         ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 9, 9, 10)     1810        ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 9, 9, 10)     5010        ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 9, 9, 10)     210         ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 9, 9, 30)     0           ['conv2d_6[0][0]',               \n",
      "                                                                  'conv2d_9[0][0]',               \n",
      "                                                                  'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 9, 9, 128)    3968        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 10368)        0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1200)         12442800    ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 600)          720600      ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 150)          90150       ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 7)            1057        ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,268,485\n",
      "Trainable params: 13,268,485\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 2s 185ms/step - loss: 1.1441 - accuracy: 0.5734 - val_loss: 0.5198 - val_accuracy: 0.8213\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 0.4107 - accuracy: 0.8462 - val_loss: 0.3876 - val_accuracy: 0.8621\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.3159 - accuracy: 0.8692 - val_loss: 0.2905 - val_accuracy: 0.8864\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 1s 164ms/step - loss: 0.2549 - accuracy: 0.8911 - val_loss: 0.2881 - val_accuracy: 0.8905\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.2045 - accuracy: 0.9266 - val_loss: 0.2572 - val_accuracy: 0.8929\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 1s 166ms/step - loss: 0.1651 - accuracy: 0.9396 - val_loss: 0.1971 - val_accuracy: 0.9213\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.1210 - accuracy: 0.9633 - val_loss: 0.1870 - val_accuracy: 0.9296\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.1049 - accuracy: 0.9680 - val_loss: 0.1695 - val_accuracy: 0.9325\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.0846 - accuracy: 0.9757 - val_loss: 0.1720 - val_accuracy: 0.9296\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 1s 197ms/step - loss: 0.0733 - accuracy: 0.9811 - val_loss: 0.1435 - val_accuracy: 0.9379\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 1s 196ms/step - loss: 0.0600 - accuracy: 0.9846 - val_loss: 0.1367 - val_accuracy: 0.9396\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 1s 196ms/step - loss: 0.0470 - accuracy: 0.9893 - val_loss: 0.1284 - val_accuracy: 0.9426\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 1s 197ms/step - loss: 0.0390 - accuracy: 0.9947 - val_loss: 0.1220 - val_accuracy: 0.9479\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.0329 - accuracy: 0.9959 - val_loss: 0.1154 - val_accuracy: 0.9515\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 1s 204ms/step - loss: 0.0330 - accuracy: 0.9935 - val_loss: 0.1162 - val_accuracy: 0.9515\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 1s 200ms/step - loss: 0.0239 - accuracy: 0.9994 - val_loss: 0.1112 - val_accuracy: 0.9485\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 1s 197ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9533\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 0.0195 - accuracy: 0.9982 - val_loss: 0.1209 - val_accuracy: 0.9462\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 1s 199ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9538\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 1s 194ms/step - loss: 0.0151 - accuracy: 0.9994 - val_loss: 0.1081 - val_accuracy: 0.9568\n",
      "951/951 [==============================] - 11s 12ms/step\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "             blood       0.98      0.98      0.98      2668\n",
      "           ketchup       0.99      0.98      0.98      5259\n",
      "  artificial blood       0.91      0.91      0.91      5774\n",
      "      poster paint       0.99      0.99      0.99      5963\n",
      "tomato concentrate       0.92      0.87      0.89      3541\n",
      "     acrylic paint       0.96      0.99      0.97      7219\n",
      "\n",
      "          accuracy                           0.96     30424\n",
      "         macro avg       0.96      0.95      0.96     30424\n",
      "      weighted avg       0.96      0.96      0.96     30424\n",
      "\n",
      "Model: \"3D_Inception_Net\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 9, 9, 15, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)                (None, 5, 5, 9, 30)  5280        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv3d_3 (Conv3D)              (None, 5, 5, 9, 40)  7040        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv3d_6 (Conv3D)              (None, 5, 5, 9, 60)  10560       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)              (None, 3, 3, 5, 20)  27020       ['conv3d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv3d_4 (Conv3D)              (None, 3, 3, 5, 20)  36020       ['conv3d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_7 (Conv3D)              (None, 3, 3, 5, 30)  81030       ['conv3d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_2 (Conv3D)              (None, 1, 1, 3, 10)  5410        ['conv3d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_5 (Conv3D)              (None, 1, 1, 3, 10)  5410        ['conv3d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_8 (Conv3D)              (None, 1, 1, 3, 10)  8110        ['conv3d_7[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 1, 1, 9, 10)  0           ['conv3d_2[0][0]',               \n",
      "                                                                  'conv3d_5[0][0]',               \n",
      "                                                                  'conv3d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_9 (Conv3D)              (None, 1, 1, 9, 128  1408        ['concatenate_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 1152)         0           ['conv3d_9[0][0]']               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 512)          590336      ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 512)          0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          65664       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 64)           8256        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 64)           0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 7)            455         ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 851,999\n",
      "Trainable params: 851,999\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 3s 395ms/step - loss: 1.8419 - accuracy: 0.2580 - val_loss: 1.4802 - val_accuracy: 0.4325\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 3s 385ms/step - loss: 1.4412 - accuracy: 0.4408 - val_loss: 1.0397 - val_accuracy: 0.5953\n",
      "Epoch 3/20\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 1.1214 - accuracy: 0.5605"
     ]
    }
   ],
   "source": [
    "# Define a list of model names\n",
    "model_names = [CNN_2D, Inception_Net_2D,Inception_Net_3D,Hybrid_Inception_Net, FC_3DCNN, Hybrid_2D_3D_CNN,Hybrid_ViT] # Add your model names here\n",
    "# model_names = [Hybrid_ViT]\n",
    "# Loop over the model names and run train_and_evaluate_model() for each model\n",
    "history_list = []\n",
    "for model_name in model_names:\n",
    "    history = train_and_evaluate_model(model_name, Tr, TrC, Va, VaC, Te, TeC, adam, output_dir, HSID, teRatio, k, WS, DLM, RDHSI, GT, Num_Classes, batch_size, epochs)\n",
    "    history_list.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss and accuracy for each model on one graph\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "colors = ['red', 'green', 'blue', 'purple', 'orange', 'gray', 'brown']\n",
    "\n",
    "for i, history in enumerate(history_list):\n",
    "    # Plot loss\n",
    "    axs[0].plot(history.history['loss'], label=f'{model_names[i].__name__} Train', color=colors[i])\n",
    "    axs[0].plot(history.history['val_loss'], label=f'{model_names[i].__name__} Val', color=colors[i], linestyle='--')\n",
    "\n",
    "    # Plot accuracy\n",
    "    axs[1].plot(history.history['accuracy'], label=f'{model_names[i].__name__} Train', color=colors[i])\n",
    "    axs[1].plot(history.history['val_accuracy'], label=f'{model_names[i].__name__} Val', color=colors[i], linestyle='--')\n",
    "\n",
    "# Add labels and legend\n",
    "axs[0].set_title('Training and Validation Loss')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_title('Training and Validation Accuracy')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].legend()\n",
    "\n",
    "# Add grid lines and set background color\n",
    "axs[0].grid(True)\n",
    "axs[1].grid(True)\n",
    "fig.patch.set_facecolor('#f2f2f2')\n",
    "plt.tight_layout()\n",
    "file_name = f\"{HSID}_{teRatio}_{k}_{WS}_{DLM}_acc_loss_curve_all_models.png\"\n",
    "plt.savefig(os.path.join(output_dir,  file_name), dpi=500)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "BloodStain_Identification_V1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
